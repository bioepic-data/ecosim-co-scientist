#!/usr/bin/env python
"""
Validate and compare NetCDF climate data against ERA5 reanalysis.

This script loads the existing Blodget climate data and validates
key variables against ERA5 reanalysis data from the same period.
"""

import cdsapi
import xarray as xr
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import tempfile
from typing import Tuple, Dict, Any


def load_blodget_climate() -> Tuple[xr.Dataset, Dict[str, Any]]:
    """
    Load the Blodget climate NetCDF file and extract metadata.
    
    Returns:
        Tuple of (dataset, metadata_dict)
    """
    climate_file = Path(__file__).parent.parent / "hackathon-case_study-experimental_warming_nitrogen" / "ecosim-inputs-netcdf" / "Blodget.clim.2012-2022.nc"
    
    print(f"Loading climate data from: {climate_file}")
    ds = xr.open_dataset(climate_file)
    
    # Extract basic metadata
    metadata = {
        "file_path": str(climate_file),
        "variables": list(ds.data_vars.keys()),
        "dimensions": dict(ds.dims),
        "time_range": (int(ds.year.min()), int(ds.year.max())),
        "grid_points": int(ds.dims["ngrid"])
    }
    
    print(f"Loaded dataset with variables: {metadata['variables']}")
    print(f"Time range: {metadata['time_range'][0]}-{metadata['time_range'][1]}")
    print(f"Grid points: {metadata['grid_points']}")
    
    return ds, metadata


def download_era5_sample(year: int = 2020, days: int = 2) -> Path:
    """
    Download a small sample of ERA5 data for validation.
    
    Downloads temperature and precipitation data for a short period
    to compare against the Blodget climate file.
    
    Args:
        year: Year to download (should be in range 2012-2022)
        days: Number of days to download (keep small for testing)
        
    Returns:
        Path to downloaded NetCDF file
    """
    # Create temporary directory for ERA5 data
    temp_dir = Path(tempfile.gettempdir()) / "era5_validation"
    temp_dir.mkdir(exist_ok=True)
    
    output_file = temp_dir / f"era5_validation_{year}_sample.nc"
    
    # Skip download if file already exists
    if output_file.exists():
        print(f"Using existing ERA5 sample: {output_file}")
        return output_file
    
    print(f"Downloading ERA5 sample for validation...")
    print(f"  Year: {year}")
    print(f"  Days: {days} days from Jan 1")
    print(f"  Variables: 2m temperature, total precipitation")
    
    # Initialize CDS API client
    try:
        client = cdsapi.Client()
    except Exception as e:
        print(f"Warning: Could not initialize CDS API client: {e}")
        print("Skipping ERA5 download - validation will use existing data only")
        return None
    
    # Download a small sample around the Pacific Northwest
    # (approximate location for comparison)
    try:
        result = client.retrieve(
            "reanalysis-era5-single-levels",
            {
                "product_type": "reanalysis",
                "variable": [
                    "2m_temperature",
                    "total_precipitation",
                ],
                "year": str(year),
                "month": "01",
                "day": [f"{i:02d}" for i in range(1, days + 1)],
                "time": [f"{h:02d}:00" for h in range(0, 24)],
                "area": [46, -123, 44, -121],  # North, West, South, East
                "format": "netcdf",
            },
        )
        
        print(f"Downloading to: {output_file}")
        result.download(str(output_file))
        print(f"âœ“ ERA5 download complete: {output_file.stat().st_size / 1024:.1f} KB")
        
    except Exception as e:
        print(f"Warning: ERA5 download failed: {e}")
        print("Proceeding with data structure validation only")
        return None
        
    return output_file


def validate_data_structure(ds: xr.Dataset) -> Dict[str, Any]:
    """
    Validate the data structure and identify any issues.
    
    Args:
        ds: Climate dataset to validate
        
    Returns:
        Dictionary with validation results
    """
    results = {
        "missing_values": {},
        "data_ranges": {},
        "temporal_coverage": {},
        "issues": []
    }
    
    # Check for missing values in key variables
    key_vars = ["TMPH", "RAINH", "SRADH", "WINDH"]
    
    for var in key_vars:
        if var in ds:
            data = ds[var]
            
            # Check for missing/fill values
            fill_value = getattr(data, "_FillValue", None)
            missing_value = getattr(data, "missing_value", None)
            
            if fill_value is not None:
                n_missing = int((data == fill_value).sum())
                results["missing_values"][var] = n_missing
                if n_missing > 0:
                    results["issues"].append(f"{var}: {n_missing} missing values (fill_value={fill_value})")
            
            # Check data ranges
            valid_data = data.where(data != fill_value) if fill_value is not None else data
            results["data_ranges"][var] = {
                "min": float(valid_data.min()),
                "max": float(valid_data.max()),
                "mean": float(valid_data.mean())
            }
            
            # Validate ranges make physical sense
            if var == "TMPH":  # Temperature in Celsius
                if results["data_ranges"][var]["min"] < -50 or results["data_ranges"][var]["max"] > 50:
                    results["issues"].append(f"{var}: Unusual temperature range ({results['data_ranges'][var]['min']:.1f} to {results['data_ranges'][var]['max']:.1f} Â°C)")
                    
            elif var == "SRADH":  # Solar radiation
                if results["data_ranges"][var]["min"] < 0 or results["data_ranges"][var]["max"] > 1500:
                    results["issues"].append(f"{var}: Unusual solar radiation range ({results['data_ranges'][var]['min']:.1f} to {results['data_ranges'][var]['max']:.1f} W/mÂ²)")
                    
            elif var == "WINDH":  # Wind speed
                if results["data_ranges"][var]["min"] < 0 or results["data_ranges"][var]["max"] > 100:
                    results["issues"].append(f"{var}: Unusual wind speed range ({results['data_ranges'][var]['min']:.1f} to {results['data_ranges'][var]['max']:.1f} m/s)")
                    
            elif var == "RAINH":  # Precipitation
                if results["data_ranges"][var]["min"] < 0 or results["data_ranges"][var]["max"] > 100:
                    results["issues"].append(f"{var}: Unusual precipitation range ({results['data_ranges'][var]['min']:.1f} to {results['data_ranges'][var]['max']:.1f} mm/hr)")
    
    # Check temporal coverage
    years = ds.year.values
    results["temporal_coverage"] = {
        "years": list(map(int, years)),
        "n_years": len(years),
        "continuous": list(range(int(years.min()), int(years.max()) + 1)) == sorted(years.tolist())
    }
    
    if not results["temporal_coverage"]["continuous"]:
        results["issues"].append("Temporal coverage is not continuous")
    
    return results


def compare_with_era5(ds: xr.Dataset, era5_file: Path) -> Dict[str, Any]:
    """
    Compare Blodget data with ERA5 reference data.
    
    Args:
        ds: Blodget climate dataset
        era5_file: Path to ERA5 NetCDF file
        
    Returns:
        Comparison results
    """
    if era5_file is None or not era5_file.exists():
        return {"status": "skipped", "reason": "ERA5 data not available"}
    
    try:
        era5_ds = xr.open_dataset(era5_file)
        print(f"Loaded ERA5 data with variables: {list(era5_ds.data_vars.keys())}")
        
        # This is a basic structure for comparison
        # In practice, would need coordinate alignment and proper mapping
        results = {
            "status": "completed",
            "era5_variables": list(era5_ds.data_vars.keys()),
            "era5_time_range": [str(era5_ds.time.min().values), str(era5_ds.time.max().values)],
            "comparison_note": "ERA5 data loaded successfully for future detailed comparison"
        }
        
        era5_ds.close()
        return results
        
    except Exception as e:
        return {"status": "failed", "error": str(e)}


def generate_validation_report(ds: xr.Dataset, metadata: Dict, validation: Dict, era5_comparison: Dict) -> str:
    """
    Generate a comprehensive validation report.
    
    Args:
        ds: Climate dataset
        metadata: Dataset metadata
        validation: Validation results
        era5_comparison: ERA5 comparison results
        
    Returns:
        Formatted report string
    """
    report = []
    report.append("# Climate Data Validation Report")
    report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    # Dataset overview
    report.append("## Dataset Overview")
    report.append(f"File: {metadata['file_path']}")
    report.append(f"Variables: {', '.join(metadata['variables'])}")
    report.append(f"Time range: {metadata['time_range'][0]}-{metadata['time_range'][1]} ({metadata['time_range'][1] - metadata['time_range'][0] + 1} years)")
    report.append(f"Grid points: {metadata['grid_points']}")
    report.append("")
    
    # Data ranges
    report.append("## Data Value Ranges")
    for var, ranges in validation["data_ranges"].items():
        units = getattr(ds[var], "units", "unknown units")
        long_name = getattr(ds[var], "long_name", var)
        report.append(f"**{var}** ({long_name})")
        report.append(f"  - Range: {ranges['min']:.2f} to {ranges['max']:.2f} {units}")
        report.append(f"  - Mean: {ranges['mean']:.2f} {units}")
    report.append("")
    
    # Missing values
    report.append("## Missing Values")
    if any(validation["missing_values"].values()):
        for var, count in validation["missing_values"].items():
            if count > 0:
                total_values = ds[var].size
                percent = (count / total_values) * 100
                report.append(f"**{var}**: {count:,} missing values ({percent:.2f}%)")
    else:
        report.append("No missing values detected in key variables.")
    report.append("")
    
    # Issues found
    report.append("## Validation Issues")
    if validation["issues"]:
        for issue in validation["issues"]:
            report.append(f"- {issue}")
    else:
        report.append("No validation issues detected.")
    report.append("")
    
    # ERA5 comparison
    report.append("## ERA5 Comparison")
    if era5_comparison["status"] == "completed":
        report.append("âœ“ ERA5 reference data loaded successfully")
        report.append(f"ERA5 variables: {', '.join(era5_comparison['era5_variables'])}")
        report.append(f"ERA5 time range: {era5_comparison['era5_time_range'][0]} to {era5_comparison['era5_time_range'][1]}")
    elif era5_comparison["status"] == "skipped":
        report.append(f"âš  ERA5 comparison skipped: {era5_comparison['reason']}")
    else:
        report.append(f"âœ— ERA5 comparison failed: {era5_comparison.get('error', 'Unknown error')}")
    report.append("")
    
    # Recommendations
    report.append("## Recommendations")
    if not validation["issues"]:
        report.append("- Data appears valid and ready for use in EcoSIM modeling")
    else:
        report.append("- Review and address validation issues before using in production")
        if any(count > 0 for count in validation["missing_values"].values()):
            report.append("- Consider gap-filling procedures for missing values")
    
    if era5_comparison["status"] != "completed":
        report.append("- Set up CDS API credentials to enable ERA5 validation")
        report.append("- Consider downloading ERA5 data for the full Blodget time period for comprehensive validation")
    
    return "\n".join(report)


def main():
    """Main validation workflow."""
    print("ğŸŒ¡ï¸  Starting climate data validation...")
    print("=" * 60)
    
    # Load Blodget climate data
    ds, metadata = load_blodget_climate()
    
    # Validate data structure and values
    print("\nğŸ“Š Validating data structure and ranges...")
    validation_results = validate_data_structure(ds)
    
    # Download ERA5 sample for comparison
    print("\nğŸŒ Downloading ERA5 reference data...")
    era5_file = download_era5_sample(year=2020, days=2)
    
    # Compare with ERA5
    print("\nğŸ” Comparing with ERA5 data...")
    era5_comparison = compare_with_era5(ds, era5_file)
    
    # Generate report
    print("\nğŸ“ Generating validation report...")
    report = generate_validation_report(ds, metadata, validation_results, era5_comparison)
    
    # Save report
    output_dir = Path(__file__).parent.parent / "output"
    output_dir.mkdir(exist_ok=True)
    report_file = output_dir / "climate_data_validation_report.md"
    
    with open(report_file, "w") as f:
        f.write(report)
    
    print(f"\nâœ… Validation complete!")
    print(f"Report saved to: {report_file}")
    print("\nSummary:")
    print(f"  - Variables validated: {len(validation_results['data_ranges'])}")
    print(f"  - Issues found: {len(validation_results['issues'])}")
    print(f"  - ERA5 comparison: {era5_comparison['status']}")
    
    # Print key issues
    if validation_results['issues']:
        print("\nâš ï¸  Key issues:")
        for issue in validation_results['issues'][:5]:  # Show first 5 issues
            print(f"    - {issue}")
    
    # Clean up
    ds.close()
    
    return report_file


if __name__ == "__main__":
    main()